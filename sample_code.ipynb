{"cells":[{"cell_type":"markdown","metadata":{"id":"ArdZhaEEUbtV"},"source":["# PBL_02 不良箇所自動検出 良否判定モデル構築用サンプルコード\n","\n","本jupyter notebookはPBL_02 不良箇所自動検出のサンプルコードです。<br>\n","**で囲まれた箇所をご自身の環境に合わせて変更いただいた上で本jupyter notebookを上から下まで実行いただけると提出可能なファイルが出力されます。<br>\n","<br>\n","本jupyter notebookの構成は以下のようになっております。<br>\n","<ol>\n","<li>Googleドライブと接続</li>\n","    Googleドライブとサンプルコードを接続する。\n","<li>ライブラリimport</li>\n","    必要なライブラリのimportを行う。\n","<li>パラメータ設定</li>\n","    画像分類アルゴリズム\"VGG\"に関する設定とデータ、ウェイトのパス設定を行う。\n","<li>VGGのネットワーク定義</li>\n","    VGGのネットワークを本課題向けにカスタマイズし、カスタマイズしたVGGを宣言する。<br>\n","    具体的には、VGGの基本設定、事前重み有無設定、出力層のカスタマイズを行う。\n","<li>学習・検証データの読み込み</li>\n","    3. で指定した格納先の学習・検証データを読み込む。\n","<li>モデルの学習</li>\n","    読み込んだデータを用いてVGGを学習させる。\n","<li>モデルによる判定</li>\n","    構築したモデルによる判定を実施する。\n","<li>学習・検証データに対する精度評価</li>\n","    学習・検証データに対する精度をF1-score、Precision、Recallで評価します\n","<li>提出ファイルの出力</li>\n","    テストデータに対して良否判定を行い、その結果を提出フォーマットであるtsv形式で出力を行う。\n","</ol>"]},{"cell_type":"markdown","metadata":{"id":"XUR-qki1eP7t"},"source":["## 1. Googleドライブと接続\n","学習データなどを読み込めるようにするため、Googleドライブとサンプルコードを接続します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nHpEomq7mQJp"},"outputs":[],"source":["# Goolgle Colaboratoryを使用する場合のみ実行。\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"z6j1AR-XUbta"},"source":["## 2. ライブラリimport\n","本サンプルコードで使用するライブラリのバージョンを指定します。<br>\n","便利なプログラムをひとまとめにし、誰でも使いやすい状態にしたものを\"ライブラリ\"と読んでいます。<br>\n","本サンプルコードでは、いくつかの\"ライブラリ\"を使用するため、使用するライブラリが何かをこちらで宣言（import ~~）しています。<br>\n","宣言することでgoogle colaboratoryはどのライブラリを使用するのか認識し、ライブラリのプログラムを使用できるようになります。<br>\n","これに関する解説はSignate Cloudの [Gym > pandas入門道場 > Introduction](https://biz.quest.signate.jp/quests/10007/contents/1) をご覧ください。<br>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IsFcSwAeUbta"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from sklearn.metrics import (\n","    f1_score,\n","    precision_score,\n","    recall_score,\n",")\n","from tensorflow import keras\n","from keras import optimizers\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing import image\n","from keras.models import Sequential, Model\n","from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Input\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras import backend as K\n","# from keras import optimizers\n","from keras.utils import np_utils\n","from keras.applications.vgg16 import VGG16\n","import keras.utils as image\n","import glob\n","import tensorflow as tf\n","tf.random.set_seed(1)\n","plt.style.use('ggplot')"]},{"cell_type":"markdown","metadata":{"id":"R8E9Kbl0Ubtc"},"source":["## 3. パラメータ設定\n","画像分類アルゴリズム\"VGG\"に関する設定とデータ・ウェイトのパス設定を行います。<br>\n","次セルの「画像分類アルゴリズム\"VGG\"に関する設定」でパラメータを変更することにより、精度向上が期待できます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f8obf27iUbtd"},"outputs":[],"source":["# 画像分類アルゴリズム\"VGG\"に関する設定\n","# 入力画像サイズの高さと幅（サイズを大きくするとより画像の特徴が明らかになり、特徴を学習しやすくなる可能性があります。一方、学習に要する時間が増えてしまいます。\n","IMG_WIDTH, IMG_HEIGHT = 224, 224\n","TARGET_SIZE = (IMG_WIDTH, IMG_HEIGHT)\n","# 判定分類数（4分類を判定するモデルを構築し、そのモデルの判別結果を最後に良品、不良品の2分類に変換する前提）\n","NB_CLASSES = 4\n","# 学習時のエポック数（学習データを何回学習させるかのパラメータ。回数を増やすとその分モデルは学習データの特徴を学習できる。ただし、学習用データに過度に適合したモデルになる可能性がある。）\n","EPOCHS = 30\n","# バッチサイズ\n","# （一度の学習で何枚の画像データを使用するかというパラメータ。100枚の学習データがあった際にバッチサイズを5とすると、5枚ずつ20回学習することを意味する。\n","# ここで言う\"一度の学習\"とは、VGGモデルが持つパラメータを更新するタイミングのことを言う。バッチサイズ5のときは、5枚のデータ毎にパラメータが更新されることになる。）\n","BATCH_SIZE = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JtGj7wTTUbtd"},"outputs":[],"source":["if K.image_data_format() == 'channels_first':\n","    input_shape = (3, IMG_WIDTH, IMG_HEIGHT)\n","else:\n","    input_shape = (IMG_WIDTH, IMG_HEIGHT, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jpvB_h-Ubte"},"outputs":[],"source":["# # データとウェイトに関する設定\n","# 学習データ保存先にはbridge, horn, potato, regularのフォルダがあり、各フォルダ配下に画像が格納されている想定\n","train_data_dir = '/content/drive/MyDrive/DXQuest/train'\n","# 検証用データ保存先にはbridge, horn, potato, regularのフォルダがあり、各フォルダ配下に画像が格納されている想定。\n","# 本サンプルコードでは、簡便さを重視し、検証用データも学習データと同じものを使用。通常、学習と検証用のデータは任意の割合で分割する\n","validation_data_dir = '/content/drive/MyDrive/DXQuest/train'\n","# テストデータ保存先には画像データが格納されている想定\n","test_data_dir = '/content/drive/MyDrive/DXQuest/test'\n","# 画像分類アルゴリズムのweightファイル保存場所\n","weight_dir = '/content/drive/MyDrive/DXQuest/weights'\n","# weightファイルの名前\n","save_weights_path = os.path.join(weight_dir, 'weights.h5') # 'weights.h5'のファイル名は変更可"]},{"cell_type":"markdown","metadata":{"id":"-FwdPDKXUbtg"},"source":["## 4. VGGのネットワーク定義\n","VGGのネットワークを本課題向けにカスタマイズします。<br>\n","具体的には、VGGの基本設定と事前重みの設定（以下「weights='imagenet'」がこれに相当）、出力層のカスタマイズなどを行います。<br>\n","事前重みの設定とは、あらかじめ様々なデータでVGGを学習させて見つけ出した良いパラメータ値をパラメータの初期値として設定することを意味します。これにより、始めからある程度汎用性のあるモデルになります。\n","更に、今回のデータでこのモデルを学習させることで学習速度を速め、かつ安定したモデルにすることを目指します。<br>\n","出力層のカスタマイズとは、今回の課題に合わせて、モデルの出力数を4種or2種に調整することを意味します。<br>\n","<br>\n","精度向上を目指すためには、以下の「VGGの学習方法の定義」セルにてoptimizerの種類と学習率を変更することが効果的かもしれません。これらに関する解説は、Signate Cloudの [Gym > DeepLearning入門〜画像分類編〜 > 畳み込みニューラルネットワーク](https://biz.quest.signate.jp/quests/10017) を参考にしてください。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ZVpu08cUbth"},"outputs":[],"source":["# VGGの基本設定と事前重みの設定\n","base_model = VGG16(\n","    weights='imagenet',\n","    include_top=False,\n","    input_tensor=Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"91Lvn-FDUbth","scrolled":true},"outputs":[],"source":["# ネットワーク構造の確認\n","base_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UR1hJQ2jUbti"},"outputs":[],"source":["# 出力層のカスタマイズ（出力に近い層を本課題に合わせて変更）\n","top_model = base_model.output\n","top_model = Flatten(name='flatten')(top_model)\n","top_model = Dense(512, activation='relu')(top_model)\n","top_model = Dropout(0.5)(top_model)\n","top_model = Dense(NB_CLASSES, activation='softmax')(top_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UI-4FV6VUbti"},"outputs":[],"source":["# カスタマイズ後のVGGの定義\n","model = Model(\n","    inputs=base_model.input,\n","    outputs=top_model\n",")\n","for layer in base_model.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZDR-BDkUbti"},"outputs":[],"source":["#  VGGの学習方法の定義\n","model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer=keras.optimizers.RMSprop(learning_rate=1e-4), #optimizerの種類（\"RMSprop\"の箇所）と学習率（\"lr\"の箇所）を変更することにより、精度向上が期待できます。\n","    metrics=['accuracy'],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cpe8gzfsUbti","scrolled":true},"outputs":[],"source":["# ネットワーク構造の確認\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"x05p82lFUbtj"},"source":["## 5. 学習・検証データの読み込み\n","3.で指定した格納先の学習・検証データを読み込みます。<br>\n","読み込み前、読み込み時にこれらのデータに前処理（特徴量の強調、クラス分布の平準化、データの分布平準化）を施すことで精度向上が期待できます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1YfGacQFUbtj"},"outputs":[],"source":["# VGGに入力できるよう画像サイズの圧縮\n","train_datagen = ImageDataGenerator(rescale=1.0/255) # 前処理を（）内に追加可能\n","valid_datagen = ImageDataGenerator(rescale=1.0/255) # 前処理を（）内に追加可能\n","# test_datagen = ImageDataGenerator(rescale=1.0/255) #要確認"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hSYeC6mHUbtj"},"outputs":[],"source":["#学習・検証データの読み込み\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=TARGET_SIZE,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n",")\n","\n","validation_generator = valid_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size=TARGET_SIZE,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ndrJnZeXUbtk"},"outputs":[],"source":["# 学習・検証データとして上記にて読み込んだ画像を設定\n","nb_train_samples = train_generator.samples\n","nb_validation_samples = validation_generator.samples"]},{"cell_type":"markdown","metadata":{"id":"p6NoNeHgUbtk"},"source":["## 6. モデルの学習\n","読み込んだ学習データを用いてVGGを学習させます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8TbLthD6Ubtk","scrolled":false},"outputs":[],"source":["model.fit(x=train_generator,\n","          epochs=EPOCHS,\n","          validation_data=validation_generator,\n","          steps_per_epoch=nb_train_samples/BATCH_SIZE,\n","          validation_steps=nb_validation_samples/BATCH_SIZE\n","          )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XMtrwkl2zhIW"},"outputs":[],"source":["if not os.path.exists(weight_dir):\n","  os.mkdir(weight_dir)\n","model.save_weights(save_weights_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iEgxv7E2Ubtk","scrolled":true},"outputs":[],"source":["# loss curveの表示\n","plt.figure(figsize=[10,8])\n","plt.plot(model.history.history['loss'], 'r')\n","plt.plot(model.history.history['val_loss'], 'b')\n","plt.legend(['Training loss', 'Validation Loss'])\n","plt.xlabel('Epochs', fontsize=16)\n","plt.ylabel('Loss', fontsize=16)\n","plt.title('Loss Curves', fontsize=16)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9uKokKdSUbtl","scrolled":true},"outputs":[],"source":["# accuracy curveの表示\n","plt.figure(figsize=[10,8])\n","plt.plot(model.history.history['accuracy'], 'r')\n","plt.plot(model.history.history['val_accuracy'], 'b')\n","plt.legend(['Training Accuracy', 'Validation Accuracy'])\n","plt.xlabel('Epochs', fontsize=16)\n","plt.ylabel('Accuracy', fontsize=16)\n","plt.title('Accuracy Curves', fontsize=16)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ls8XtECgUbtl"},"source":["## 7. モデルによる判定\n","学習・検証用データに構築したモデルで良品、不良品の判定を行います。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VhSZQek3Ubtl"},"outputs":[],"source":["# weightファイルの読み込み\n","print('load model...')\n","model.load_weights(save_weights_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NRJxRGtGUbtl"},"outputs":[],"source":["# 良否判定実行関数\n","def get_predict(model,\n","                train_data_dir: str,\n","                test_data_dir: str):\n","    \"\"\"This function will performs model inferencing using test data\n","    and stores the results into the lists.\n","\n","    Args:\n","        model (object): The trained model.\n","        train_data_dir (str): The location of train images.\n","        test_data_dir (str): The location of test images.\n","\n","    Returns:\n","        filenames (list): filenames of predicted images.\n","        true_classes (list): true classes of predicted images.\n","        pred_classes (list): prediction classes of predicted images.\n","    \"\"\"\n","\n","    data_datagen = ImageDataGenerator(rescale=1/255.)\n","\n","    test_generator = data_datagen.flow_from_directory(\n","        test_data_dir,\n","        target_size=TARGET_SIZE,\n","        class_mode=None,\n","        batch_size=1,\n","        shuffle=False,\n","    )\n","    preds = model.predict_generator(test_generator)\n","\n","    preds_class_idx = preds.argmax(axis=-1)\n","\n","    # get prediction class\n","    train_datagen = ImageDataGenerator(rescale=1./255)\n","\n","    train_generator = train_datagen.flow_from_directory(\n","        train_data_dir,\n","        target_size=TARGET_SIZE,\n","        batch_size=BATCH_SIZE,\n","    )\n","\n","    idx_to_class = {v: k for k, v in train_generator.class_indices.items()}\n","    pred_classes = np.vectorize(idx_to_class.get)(preds_class_idx)\n","    filenames_to_class = list(zip(test_generator.filenames, pred_classes))\n","\n","    # get true class\n","    filenames = []\n","    true_classes = []\n","\n","    for item in test_generator.filenames:\n","        filenames.append(item)\n","        # get true class from the filenames\n","        true_class = item.split('/')[0]\n","        true_classes.append(true_class)\n","\n","    return filenames, true_classes, pred_classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QkvF2sCVUbtm"},"outputs":[],"source":["# 精度算出関数\n","def get_f1(true_labels_list: list,\n","           predictions_list: list,\n","           average_method: str,\n","          ) -> (float, float, float):\n","    \"\"\"This function will performs model inferencing using test data\n","    and stores the results into the lists.\n","\n","    Args:\n","        true_labels_list (list): List of true labels.\n","        predictions_list (list): List of predictions.\n","        average_method (string): method to average score.\n","\n","    Returns:\n","        f1 (float): return f1 metric.\n","        precision (float): return precision metric.\n","        recall (float): return recall metric.\n","    \"\"\"\n","    f1 = f1_score(\n","        y_true=true_labels_list,\n","        y_pred=predictions_list,\n","        average=average_method\n","    )\n","\n","    precision = precision_score(\n","        y_true=true_labels_list,\n","        y_pred=predictions_list,\n","        average=average_method,\n","    )\n","\n","    recall = recall_score(\n","        y_true=true_labels_list,\n","        y_pred=predictions_list,\n","        average=average_method,\n","    )\n","\n","    f1 = round(f1, 2)\n","    precision = round(precision, 2)\n","    recall = round(recall, 2)\n","\n","    return f1, precision, recall"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pRp51Ow0Ubtm","scrolled":false},"outputs":[],"source":["# 良否判定実行\n","train_filenames, train_true_classes, train_pred_classes = get_predict(\n","    model=model,\n","    train_data_dir=train_data_dir,\n","    test_data_dir=train_data_dir,\n",")\n","valid_filenames, valid_true_classes, valid_pred_classes = get_predict(\n","    model=model,\n","    train_data_dir=train_data_dir,\n","    test_data_dir=validation_data_dir,\n",")"]},{"cell_type":"markdown","metadata":{"id":"NHFlW842Ubtm"},"source":["## 8. 学習・検証データに対する精度評価\n","学習・検証データに対する精度をF1-score、Precision、Recallで評価します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aeGTHSO5Ubtm"},"outputs":[],"source":["# 精度算出\n","train_f1, train_prec, train_recall = get_f1(\n","    true_labels_list=train_true_classes,\n","    predictions_list=train_pred_classes,\n","    average_method='weighted',\n",")\n","valid_f1, valid_prec, valid_recall = get_f1(\n","    true_labels_list=valid_true_classes,\n","    predictions_list=valid_pred_classes,\n","    average_method='weighted',\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jlq2ugpcUbtm"},"outputs":[],"source":["# 精度表示\n","print('{:15}{:<15.2f}{:<15.2f}'.format('F1-score:', train_f1, valid_f1))\n","print('{:15}{:<15.2f}{:<15.2f}'.format('Precision:', train_prec, valid_prec))\n","print('{:15}{:<15.2f}{:<15.2f}'.format('Recall:', train_recall, valid_recall))"]},{"cell_type":"markdown","metadata":{"id":"naWyl3-tUbtm"},"source":["## 9. 提出ファイルの出力\n","テストデータに対して良否判定を行い、その結果を提出フォーマットであるtsv形式で出力を行います。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U2dOfSFyUbtn"},"outputs":[],"source":["# 分類とラベルの対応確認\n","label_map = (train_generator.class_indices)\n","print(label_map)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VN4yUt_MUbtn","scrolled":false},"outputs":[],"source":["# テストデータに対して1つずつ予測し、テストデータのファイル名と判定結果をリストに保存\n","file_list = []\n","pred_list = []\n","for file in glob.glob(test_data_dir + '/*'):\n","    image_data = file\n","    filename = file.split('/')[-1]\n","    img = image.load_img(image_data, target_size=(IMG_WIDTH, IMG_HEIGHT))\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    x = x / 255\n","    pred = model.predict(x)[0]\n","    judge = np.argmax(pred)\n","\n","    # *bridge, horn, potatoを不良（'1'）に、regularを良品（'0'）に変換。if文の条件分岐は上の「分類とラベルの対応確認」セルの結果を参考に変更すること*\n","    if judge==0:\n","        judge=1\n","    elif judge==1:\n","        judge=1\n","    elif judge==2:\n","        judge=1\n","    else:\n","        judge=0\n","\n","    pred_list.append(judge)\n","    file_list.append(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d_1242zKUbtn"},"outputs":[],"source":["#判別結果をDataFrameに変換し、tsvファイルに出力\n","df = pd.DataFrame([file_list, pred_list]).T\n","df.to_csv('/content/drive/MyDrive/DXQuest/my_submission.tsv',\n","         index=False,\n","         header=False,\n","         sep='\\t')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}