{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🐯PyTorch版サンプルコード\n",
    "\n",
    "公式のサンプルコードは2～3年前に作成されたもので、利用数が減ってきているTensorFlowが使われています。  \n",
    "現在はPyTorchが主流であるため、このコードは、公式サンプルコードと同様の処理をPyTorch版に書き換えた物です。  \n",
    "また、効率的に開発するため、PyTorchとセットで利用されることが多いPyTorch Lightningも使用しています。\n",
    "\n",
    "このコードは、Google Colab（2024年8月21日時点）や、ローカルのDocker環境で動作確認済みです。\n",
    "\n",
    "コード作成： PBL02「🐯とら」チーム CM_Kurozumi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔖環境の事前準備\n",
    "\n",
    "Google Colab で動かしている場合は、以下の前準備処理を行います。  \n",
    "Google Drive への接続確認画面が表示されたら、指示に従って接続してください。\n",
    "\n",
    "- 必要なPythonパッケージをインストール（PyTorch Lightning と TorchMetrics）\n",
    "- Google Drive への接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Google Colab 上で実行しているかどうか\n",
    "ON_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "# fmt: off\n",
    "if ON_COLAB:\n",
    "    print(\"Running on Google Colab.\")\n",
    "    # 必要なライブラリをインストール\n",
    "    !pip install lightning==2.4.0 torchmetrics==1.4.1\n",
    "\n",
    "    # Google Drive にマウント\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "else:\n",
    "    print(\"Not running on Google Colab.\")\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "処理に必要なパッケージを読み込みます。  \n",
    "主にPyTorch系のパッケージが中心になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pytorch_lightning.callbacks import Callback, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics import Accuracy, F1Score, Precision, Recall\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔖データフォルダの指定\n",
    "\n",
    "利用環境に合わせて、学習などに利用する画像ファイルのデータフォルダ `DATA_DIR` と、  \n",
    "学習時のログや結果を格納するログフォルダ `LOGS_DIR` を指定します。\n",
    "\n",
    "Google Colab を使っている場合は、Google Drive に `DXQuest` というフォルダが作成され、  \n",
    "その中に `train`, `test` などの画像データが格納されている想定にしています。\n",
    "\n",
    "このパス情報は、利用している環境に合わせて適宜書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用するフォルダ名（Colabかどうかでパスを変更）\n",
    "DATA_DIR = \"/content/drive/MyDrive/DXQuest\" if ON_COLAB else \"/workspace/data\"\n",
    "LOGS_DIR = \"/content/drive/MyDrive/logs\" if ON_COLAB else \"/workspace/logs\"\n",
    "\n",
    "print(\"Data folder:\", DATA_DIR)\n",
    "print(\"Logs folder:\", LOGS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔖共通パラメータの設定\n",
    "\n",
    "学習時の「バッチサイズ」や、クラス数の設定を行います。\n",
    "\n",
    "また、内部で利用されている乱数のシード値を固定して、再実行時の再現性を高めています。  \n",
    "乱数値のシードは `42` を指定していますが、この値に大きな意味は無いので、好きな数字にしてOKです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# 各種乱数の固定\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔖学習と検証データセットの定義\n",
    "\n",
    "学習と検証に利用するデータに関する処理です。  \n",
    "学習用と検証用に、それぞれ以下の処理を定義します。\n",
    "\n",
    "- 実際に利用するデータの集まり（dataset）\n",
    "- 各画像に対する加工処理（transform）\n",
    "- データセットからデータを取り出す処理（data_loader）\n",
    "\n",
    "💡学習データと検証データ\n",
    "\n",
    "- 本来は、学習用と検証用のデータは「別のデータ」を利用します\n",
    "- ただし、ここでは公式サンプルと同様に `train` のデータを検証でも利用するようにしています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットのディレクトリ\n",
    "train_dir = os.path.join(DATA_DIR, \"train\")\n",
    "val_dir = os.path.join(DATA_DIR, \"train\")  # 検証にもtrainデータを使う（本来は別のデータを使うべき）\n",
    "\n",
    "# データ変換\n",
    "data_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),  # ResNet用に画像サイズを調整\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "WORKERS = 2\n",
    "\n",
    "# データセットとデータローダー（ラベルはフォルダ名から自動で設定される）\n",
    "train_dataset = ImageFolder(train_dir, transform=data_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, pin_memory=True)\n",
    "\n",
    "# Note:サンプルコードではvalidationデータもtrainデータと同じものを使っているが、本来は別のデータを使うべき！\n",
    "val_dataset = ImageFolder(val_dir, transform=data_transforms)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ImageFolder` を使ってデータセットを作成すると、フォルダ名で自動で正解ラベルが設定されます。  \n",
    "実際に設定された「正解ラベルと、その値」は、datasetの `class_to_idx` で確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自動で設定されたラベル番号とラベル名の確認\n",
    "print(train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔖モデルなどの定義\n",
    "\n",
    "学習に利用するモデルの定義などを行います。  \n",
    "ここでは、利用するモデルの種類や構造、損失関数、最適化手法などを定義します。  \n",
    "また、学習の各ステップごとに行う処理も定義できます。\n",
    "\n",
    "今回はResNet18を利用して、4クラス分類を行うモデルを作成します。\n",
    "\n",
    "Accuracy, Precision, Recall, F1-Scoreなどの計算も、torchmetricsを使って簡単に計算できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル定義\n",
    "class ResNetClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(self.model.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.precision = Precision(task=\"multiclass\", num_classes=num_classes, average=\"weighted\")\n",
    "        self.recall = Recall(task=\"multiclass\", num_classes=num_classes, average=\"weighted\")\n",
    "        self.f1 = F1Score(task=\"multiclass\", num_classes=num_classes, average=\"weighted\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True)\n",
    "        self.log(\"train_acc\", self.accuracy(outputs, labels), on_epoch=True)\n",
    "        self.log(\"train_precision\", self.precision(outputs, labels), on_epoch=True)\n",
    "        self.log(\"train_recall\", self.recall(outputs, labels), on_epoch=True)\n",
    "        self.log(\"train_f1\", self.f1(outputs, labels), on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True)\n",
    "        self.log(\"val_acc\", self.accuracy(outputs, labels), on_epoch=True)\n",
    "        self.log(\"val_precision\", self.precision(outputs, labels), on_epoch=True)\n",
    "        self.log(\"val_recall\", self.recall(outputs, labels), on_epoch=True)\n",
    "        self.log(\"val_f1\", self.f1(outputs, labels), on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # 最適化関数と学習率スケジューラーの設定（性能が向上しなくなったら学習率を減らす）\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=3)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        images, _ = batch\n",
    "        outputs = self(images)\n",
    "        return torch.argmax(outputs, dim=1)\n",
    "\n",
    "\n",
    "# 各エポックごとの結果を表示するコールバック\n",
    "class PrintCallback(Callback):\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        metrics = trainer.callback_metrics\n",
    "        print(\n",
    "            f\" [{trainer.current_epoch:03}] \"\n",
    "            f\"loss: {metrics['train_loss']:.4f}, \"\n",
    "            f\"acc: {metrics['train_acc']:.4f}, \"\n",
    "            f\"precision: {metrics['train_precision']:.4f}, \"\n",
    "            f\"recall: {metrics['train_recall']:.4f}, \"\n",
    "            f\"f1: {metrics['train_f1']:.4f}, \"\n",
    "            f\"val_loss: {metrics['val_loss']:.4f}, \"\n",
    "            f\"val_acc: {metrics['val_acc']:.4f}, \"\n",
    "            f\"val_precision: {metrics['val_precision']:.4f}, \"\n",
    "            f\"val_recall: {metrics['val_recall']:.4f}, \"\n",
    "            f\"val_f1: {metrics['val_f1']:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔖学習計画の準備\n",
    "\n",
    "PyTorch Lightning を使って、学習の準備を行います。  \n",
    "全体的な学習の管理を行うような「トレーナー」の設定になります。\n",
    "\n",
    "`MAX_EPOCHS` の値を変更すれば、学習させる最大回数（エポック数）を変更できます。  \n",
    "また、学習が進まなくなった場合は、そこで学習をストップさせるEarlyStoppingも設定しています。\n",
    "\n",
    "💡EarlyStoppingに関する注意点\n",
    "ここでは `val_loss`（検証用データに対する結果）が、3回連続で改善されない場合はストップさせる設定にしています。  \n",
    "ただし、本サンプルコードでは、検証用データも「学習用データをそのまま使う」形にしているため、この状態では「val_lossに対する結果は常に良くなり続ける（そして過学習が起きる）」ため、EarlyStoppingが発動することは無いと思われます。  \n",
    "EarlyStoppingは、学習用データと検証用データをきちんと分けた場合に効果を発揮します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 10\n",
    "\n",
    "# 学習時のログ記録（必要に応じてW&Bなどのログサービスを利用可能）\n",
    "logger = None\n",
    "\n",
    "# EarlyStoppingの設定\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n",
    "\n",
    "# Trainerの設定\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=LOGS_DIR,\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=5,\n",
    "    callbacks=[early_stopping, PrintCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔖学習\n",
    "\n",
    "上記で定義したトレーナーが、自動で学習を進めていきます。  \n",
    "学習に利用するデータ量やモデルの種類、環境などによって、学習時間は大きく異なります。\n",
    "\n",
    "学習には数分～数時間程度の時間がかかります。\n",
    "\n",
    "学習済みのモデルウェイトは `LOGS_DIR` で指定したフォルダ配下の、  \n",
    "`lightning_logs/version_n/checkpoints` フォルダ配下に保存されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Coreが使える場合は利用する\n",
    "# https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# モデルのトレーニング\n",
    "model = ResNetClassifier()\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔖学習済みモデルの読み込み\n",
    "\n",
    "学習したモデルウェイトを読み込みます。  \n",
    "学習する度に、学習済みのウェイトファイル（*.ckpt）ファイルが作成されるため、ファイルをリストアップしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みのウェイトファイルをリストアップ\n",
    "def enum_checkpoints(dir_path: str = LOGS_DIR) -> list:\n",
    "    checkpoint_files = []\n",
    "    for root, _, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".ckpt\"):\n",
    "                checkpoint_files.append(os.path.join(root, file))\n",
    "    return sorted(checkpoint_files)\n",
    "\n",
    "\n",
    "checkpoints = enum_checkpoints()\n",
    "checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記で取得したウェイトファイルの一覧から「最新のウェイト情報」を選んで読み込んでいます。  \n",
    "最後のウェイトファイルが最も精度が高いとは限らないため、必要に応じて読み込むウェイトファイルは変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUが使える場合はGPUを使う（GPUがない場合はCPUを使う）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# 学習済みのウェイト情報を読み込む\n",
    "ckpt_file = checkpoints[-1]  # 最新のウェイトを読み込む（必要に応じて変更）\n",
    "print(\"Checkpoint:\", ckpt_file)\n",
    "checkpoint = torch.load(ckpt_file)\n",
    "model = ResNetClassifier()\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔖テストデータの読み込み\n",
    "\n",
    "test画像に対して推論していくため、テスト画像用の dataset, data_loader を定義します。  \n",
    "画像を加工する処理は、trainなどで作成した transform をそのまま利用します。\n",
    "\n",
    "testデータには正解ラベルが無い（regularなどの正解ラベルのフォルダが存在しない）ため、  \n",
    "専用の `UnlabeledImageDataset` を定義します。（ImageFolderは正解ラベルのフォルダが無いと利用できないため）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageLoaderはラベル付きのデータセットを読み込むため、ラベルなしのデータセットを読み込むためのクラスを作成\n",
    "class UnlabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = [\n",
    "            os.path.join(image_dir, img) for img in os.listdir(image_dir) if img.endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "\n",
    "# /workspace/data/test から実際に推論する画像データを読み込み\n",
    "test_dir = os.path.join(DATA_DIR, \"test\")\n",
    "test_dataset = UnlabeledImageDataset(test_dir, transform=data_transforms)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE, num_workers=WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔖テスト画像に対して推論\n",
    "\n",
    "読み込んだテスト画像に対して、学習済みモデルで推論を行っていきます。  \n",
    "推論結果は、各画像に対して 0～3 の学習時に使用した正解ラベルの番号（0=bridge など）で返ってきます。\n",
    "\n",
    "全ての画像に対する推論結果を、リスト形式に成形して取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータに対して推論\n",
    "all_preds = []\n",
    "for i, images in enumerate(test_loader):\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.tolist())\n",
    "\n",
    "print(all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔖推論結果をDataFrameで整理\n",
    "\n",
    "最終的には「ファイル名と、良品=0/不良品=1」の値をセットで出力する必要があるため、DataFrame型で表形式で整理します。\n",
    "\n",
    "分かりやすいように、予測結果の数値（0～3）に対するラベルや、  \n",
    "最終的な「regular=0（良品）、それ以外は1（不良品）」という形への変換も、ここで行います。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータのパスと、推論結果をDataFrameにまとめる\n",
    "df = pd.DataFrame({\"path\": test_dataset.image_paths, \"pred\": all_preds})\n",
    "\n",
    "# ラベル、ファイル名、提出用の予測結果（良品=0/不良品=1）を追加\n",
    "df[\"label\"] = df[\"pred\"].apply(lambda x: train_dataset.classes[x])  # ラベル（例: \"regular\"）\n",
    "df[\"filename\"] = df[\"path\"].apply(lambda x: os.path.basename(x))  # ファイル名（例: \"003.jpeg\"）\n",
    "df[\"y_hat\"] = df[\"label\"].apply(lambda x: 0 if x == \"regular\" else 1)  # 良品=0/不良品=1\n",
    "\n",
    "# ファイル名の昇順にソートしてインデックスの振り直し\n",
    "df = df.sort_values(\"filename\").reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔖指定された形式でTSVファイルに保存\n",
    "\n",
    "最終的に提出するTSVファイルを作成します。  \n",
    "中身も「ファイル名と0/1」の値のセットをタブ区切りで出力する必要があるため、この形式で出力しています。\n",
    "\n",
    "TSVファイルは `DATA_DIR` フォルダ配下に、 my_submission_{日時}.tsv というファイル名で出力されます。  \n",
    "このファイルを、SIGNATE Cloud 経由で提出しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存するファイル名の設定（現在日時を付けておく）\n",
    "now_str = pd.Timestamp.now(tz=\"Asia/Tokyo\").strftime(\"%Y%m%d_%H%M%S\")\n",
    "tsv_filename = os.path.join(DATA_DIR, f\"my_submission_{now_str}.tsv\")\n",
    "\n",
    "# filename, y_hat の項目だけをtsvファイルに保存（ヘッダ無し）\n",
    "df[[\"filename\", \"y_hat\"]].to_csv(tsv_filename, sep=\"\\t\", header=False, index=False)\n",
    "print(\"Saved:\", tsv_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
